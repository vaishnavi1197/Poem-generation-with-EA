{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jennifergutman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import syllables \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import language_tool_python\n",
    "from IPython.display import display\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import timeit\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jennifergutman/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gingerit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Dataset_poems.txt\", \"r\",encoding=\"utf8\") as file:\n",
    "    # Trial_data.txt\n",
    "    # Dataset_poems.txt\n",
    "    temp = []\n",
    "    for line in file:\n",
    "        line1 = re.sub('[^a-zA-Z ]', '', line)\n",
    "        line1 = line1.split()\n",
    "        if line1 != ['', ''] and line1 != ['']:\n",
    "            for i in line1:\n",
    "                if i == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    temp.append(i.lower())\n",
    "words_df = temp[:5000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tag = pos_tag(words_df)\n",
    "dic_tag = {}\n",
    "for tup in tokens_tag:\n",
    "  if tup[1] not in dic_tag.keys():\n",
    "    dic_tag[tup[1]] = [tup[0]]\n",
    "  else:\n",
    "    temp = dic_tag[tup[1]] + [tup[0]]\n",
    "    dic_tag[tup[1]] = temp\n",
    "# print(dic_tag.keys())\n",
    "z = list(dic_tag.values())\n",
    "words_df2 = []\n",
    "for i in range(len(z)):\n",
    "  words_df2.extend(z[i])\n",
    "# print(words_df2)\n",
    "words_df = words_df2\n",
    "words_df.remove('o')\n",
    "words_df.remove('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for i in range(3, len(words_df)-3):\n",
    "    lines.append(words_df[i-3]+' '+' '+words_df[i-2]+' '+' '+words_df[i-1]+' '+' '+words_df[i]+' '+' '+words_df[i+1]+' '+' '+words_df[i+2]+' '+' '+words_df[i+3])\n",
    "\n",
    "# sklearn countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "cv = CountVectorizer(ngram_range=(1,1), stop_words = stopwords.words('english'))\n",
    "# matrix of token counts\n",
    "X = cv.fit_transform(lines)\n",
    "Xc = (X.T * X) # matrix manipulation\n",
    "Xc.setdiag(0) # set the diagonals to be zeroes as it's pointless to be 1\n",
    "\n",
    "names = cv.get_feature_names() # This are the entity names (i.e. keywords)\n",
    "cooccur_df = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)\n",
    "total = cooccur_df.to_numpy().sum()\n",
    "cooccur_df = cooccur_df.div(total)\n",
    "cooccur_df.to_csv('co_occur_mat.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poem_generation:\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    def select_random_words(self,words_df):\n",
    "        words_array1 = []\n",
    "        while len(words_array1) <= 15:\n",
    "            random_number = random.randint(0, len(words_df)-1)\n",
    "            if words_df[random_number] != 0:\n",
    "                words_array1.append(words_df[random_number])\n",
    "        # print(len(words_array1))\n",
    "\n",
    "        return words_array1\n",
    "\n",
    "    def create_poems(self,arr):\n",
    "        poem = [0 for _ in range(4)]\n",
    "        for i in range(1,5):\n",
    "            temp =  arr[4*(i-1):4*i]\n",
    "            poem[i-1] = temp\n",
    "            # print(\"HERE:\",temp)\n",
    "            # print(type(temp))\n",
    "            poem[i-1]=' '.join(poem[i-1])\n",
    "            # print(poem[i-1])\n",
    "        # print(\"=========================================================\")\n",
    "        return poem\n",
    "\n",
    "    def store_syllables(self,arr):\n",
    "        a = [0 for _ in range(4)]\n",
    "        temp = 0\n",
    "        j = 0\n",
    "        for words,i in zip(arr,range(0,16)):\n",
    "            temp = temp + syllables.estimate(words)\n",
    "            if i in [3,7,11,15]:\n",
    "                a[j] = temp\n",
    "                # print(a[j])\n",
    "                temp = 0\n",
    "                j += 1\n",
    "        return a\n",
    "\n",
    "    def Grammar_checker(self,text):\n",
    "        error = 0\n",
    "        poem_error = []\n",
    "        # tool = language_tool_python.LanguageTool('en-US')\n",
    "        for lines in text:\n",
    "            matches = tool.check(lines)\n",
    "            if len(matches)>0:\n",
    "                error = error + matches[0].errorLength\n",
    "        poem_error.append(error)\n",
    "        return poem_error\n",
    "\n",
    "    def crossover(self,p1,p2,cross):\n",
    "        part1 = []\n",
    "        part2 = []\n",
    "        part3 = []\n",
    "        child1 = []\n",
    "        child2 = []\n",
    "        j = 0\n",
    "        k = 0\n",
    "        random_number1 = sorted([random.randint(1, 15) for i in range(cross)])\n",
    "        random_number2 = sorted([random.randint(1, 15) for i in range(cross)])\n",
    "        for i in random_number1:\n",
    "            part1.append(p1[j:i])\n",
    "            j = i\n",
    "        for i in random_number2:\n",
    "            part2.append(p2[k:i])\n",
    "            k = i\n",
    "        part1.append(p1[j:])\n",
    "        part2.append(p2[k:])\n",
    "        part2.extend(part1)\n",
    "        random.shuffle(part2)\n",
    "        for i in range(len(part2)):\n",
    "            part3.extend(part2[i])\n",
    "        for i in range(int(len(part3)/2)):\n",
    "            child1.append(part3[i])\n",
    "        for i in range(int(len(part3)/2),int(len(part3))):\n",
    "            child2.append(part3[i])\n",
    "        # if child1 == p1 or child1 == p2 or child2 == p1 or child2 == p2:\n",
    "        #     child1, child2,child1_poem,child2_poem = self.crossover(child1,child2,cross)\n",
    "        child1_poem = self.create_poems(child1)\n",
    "        child2_poem = self.create_poems(child2)\n",
    "        return child1,child2,child1_poem,child2_poem\n",
    "    \n",
    "    def coherence_checker(self, text):\n",
    "        clean_text = ''\n",
    "        for i in text:\n",
    "            clean_text = clean_text + ' ' + i\n",
    "        \n",
    "        text_tokens = word_tokenize(clean_text)\n",
    "        tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "        \n",
    "        coherence_val = 0\n",
    "        for i in range(len(tokens_without_sw) - 1):\n",
    "            for j in range(i+1, len(tokens_without_sw)):\n",
    "                coherence_val += cooccur_df[tokens_without_sw[i]][tokens_without_sw[j]]\n",
    "            \n",
    "        coherence_val /= (len(tokens_without_sw)-1)\n",
    "        #coherence_val\n",
    "        return [coherence_val]\n",
    "\n",
    "    def tournament(self,Population,m,best):\n",
    "        from_best = len(best)\n",
    "        # print(\"best:\",best)\n",
    "        except_best = m - from_best\n",
    "        # df = pd.DataFrame()\n",
    "        #selected_polulation = pd.DataFrame(columns=[\"Line1\",\"Line2\",\"Line3\",\"Line4\",\"Syllables1\",\"Syllables2\",\"Syllables3\",\"Syllables4\",\"GrammarError\",\"word_array\"])\n",
    "        ######################### when no syllables rule\n",
    "        # selected_polulation = Population.iloc[:nn]\n",
    "        # random_number = random.sample(list(Population.iloc[nn:].index),p)\n",
    "        # Population.sort_values(by=['GrammarError'], inplace=True)\n",
    "        # Population2 = Population[~Population.isin(selected_polulation).all(1)]\n",
    "        ######################### when syllables rule\n",
    "        if len(best) >0:\n",
    "            selected_polulation = []\n",
    "            words_array_selected = []\n",
    "            for b in best:\n",
    "                c = Population.iloc[b].values[:-1]\n",
    "                d = Population.iloc[b].values[-1]\n",
    "                selected_polulation.append(c)\n",
    "                words_array_selected.append(d)\n",
    "            words_array_selected = pd.DataFrame(dict(zip([\"words_array\"],[words_array_selected])))\n",
    "            \n",
    "############# This line was changed with addition of fitness column \n",
    "            #selected_polulation = pd.DataFrame(selected_polulation,columns=[\"Line1\",\"Line2\",\"Line3\",\"Line4\",\"Syllables1\",\"Syllables2\",\"Syllables3\",\"Syllables4\",\"GrammarError\",\"Coherence\"])\n",
    "            selected_polulation = pd.DataFrame(selected_polulation,columns=[\"Line1\",\"Line2\",\"Line3\",\"Line4\",\"Syllables1\",\"Syllables2\",\"Syllables3\",\"Syllables4\",\"GrammarError\",\"Coherence\",\"Gram Rank\",\"Coh Rank\",\"Syll_Bonus\",\"Fitness\"])\n",
    "            \n",
    "            selected_polulation = pd.concat([selected_polulation,words_array_selected],axis=1)\n",
    "            # print(\"poems selected by user\")\n",
    "            # display(selected_polulation)\n",
    "            Population2 = Population[~Population.isin(selected_polulation).all(1)]\n",
    "            Population2 = Population2.sort_values(by=['GrammarError'])\n",
    "            selected_polulation2 = Population2[(Population2[\"Syllables1\"] == \"5\")&(Population2[\"Syllables2\"] == \"6\")&(Population2[\"Syllables3\"] == \"6\")&(Population2[\"Syllables4\"] == \"5\")]\n",
    "            # selected_polulation2 = Population2[(Population2[\"Syllables1\"] >= \"3\")]\n",
    "            # print(\"grammar sorted poems by syll\")\n",
    "            # display(selected_polulation2)\n",
    "            from_sy = len(selected_polulation2.index)\n",
    "            if from_sy >= int(except_best/2):\n",
    "                from_sy = int(except_best/2)\n",
    "            else:\n",
    "                from_sy = from_sy\n",
    "            from_random = except_best - from_sy\n",
    "            selected_polulation2 = selected_polulation2.iloc[:from_sy]\n",
    "            selected_polulation = pd.concat([selected_polulation,selected_polulation2],axis=0)\n",
    "            selected_polulation = selected_polulation.reset_index(drop=True)\n",
    "            display(selected_polulation)\n",
    "            display(Population2)\n",
    "            Population2 = Population2[~Population2.isin(selected_polulation).all(1)]\n",
    "            Population2 = Population2.reset_index(drop=True)\n",
    "            selected_polulation = pd.concat([selected_polulation,Population2.iloc[:from_random]],axis=0)\n",
    "            selected_polulation = selected_polulation.reset_index(drop=True)\n",
    "            # print(\"SELECTED\")\n",
    "            # display(selected_polulation)\n",
    "            words_array_selected = list(selected_polulation[\"words_array\"])\n",
    "            # print(\"TYPE\",type(selected_polulation[\"words_array\"]),words_array_selected)\n",
    "            return selected_polulation,words_array_selected\n",
    "        else:\n",
    "            Population2 = Population.sort_values(by=['GrammarError'])\n",
    "            random = int(except_best/3)\n",
    "            grammar = except_best - random\n",
    "            selected_polulation = Population2[:grammar]\n",
    "            Population2 = Population2[~Population2.isin(selected_polulation).all(1)]\n",
    "            selected_polulation2 = Population2[:random]\n",
    "            selected_polulation = pd.concat([selected_polulation,selected_polulation2],axis=0)\n",
    "            selected_polulation = selected_polulation.reset_index(drop=True)\n",
    "            # print(\"SELECTED\")\n",
    "            # display(selected_polulation)\n",
    "            words_array_selected = list(selected_polulation[\"words_array\"])\n",
    "            # print(\"TYPE\",type(selected_polulation[\"words_array\"]),words_array_selected)\n",
    "            return selected_polulation,words_array_selected\n",
    "\n",
    "\n",
    "\n",
    "    def create_set_of_poems(self,n):\n",
    "            poem_population = []\n",
    "            syllables_count = []\n",
    "            grammar_error = []\n",
    "            words_array_population = []\n",
    "            coherence_arr = []\n",
    "            for i in range(n):\n",
    "                words_array = self.select_random_words(words_df)\n",
    "                poem = self.create_poems(words_array)\n",
    "                sum_syllables = self.store_syllables(words_array)\n",
    "                poem_error = self.Grammar_checker(poem)\n",
    "                coherence = self.coherence_checker(poem)\n",
    "                poem_population.append(poem)\n",
    "                syllables_count.append(sum_syllables)\n",
    "                grammar_error.append(poem_error)\n",
    "                coherence_arr.append(coherence)\n",
    "                words_array_population.append(words_array)\n",
    "            words_array2 = pd.DataFrame(dict(zip([\"words_array\"],[words_array_population])))\n",
    "            Final = np.hstack((poem_population,syllables_count,grammar_error,coherence_arr))\n",
    "            Population_data = pd.DataFrame(Final,columns=[\"Line1\",\"Line2\",\"Line3\",\"Line4\",\"Syllables1\",\"Syllables2\",\"Syllables3\",\"Syllables4\",\"GrammarError\",\"Coherence\"])\n",
    "            \n",
    "############# Calculate Fitness of Poems\n",
    "            max_rank = len(Population_data[\"Line1\"])\n",
    "            Population_data[\"Gram_Rank\"] = Population_data[\"GrammarError\"].rank(method = 'min', ascending = False)\n",
    "            Population_data[\"Coherence\"] = Population_data[\"Coherence\"].apply(lambda x: [float(el) for el in x.strip(\"[]\").split(\",\")])\n",
    "            Population_data[\"Coh_Rank\"] = Population_data[\"Coherence\"].rank(method = 'min')\n",
    "            Population_data[\"Syll_Bonus\"] = Population_data.apply(lambda row: 1 if ((row.Syllables1 == 5)&(row.Syllables2 == 6)&(row.Syllables3 == 6)&(row.Syllables4 == 5)) else 0, axis = 1)\n",
    "            Population_data[\"Fitness\"] = Population_data.apply(lambda row: 0.4*row.Gram_Rank/max_rank + 0.4*row.Coh_Rank/max_rank + 0.2*row.Syll_Bonus, axis = 1)\n",
    "###########            \n",
    "            Pop_data = pd.concat([Population_data,words_array2],axis=1)\n",
    "            # print()\n",
    "            # print(\"PARENTS\")\n",
    "            # display(Pop_data)\n",
    "\n",
    "            return Pop_data\n",
    "\n",
    "    def child_poems(self,words_array,cross):\n",
    "        child_population = []\n",
    "        syllables_count = []\n",
    "        grammer_error = []\n",
    "        words_array_child = []\n",
    "        coherence_arr = []\n",
    "        # print(\"words_array\",words_array)\n",
    "        # print(type(words_array))\n",
    "        if len(words_array)%2 == 2:\n",
    "            for i in range(0,len(words_array)-1):\n",
    "                child1,child2,child1_poem,child2_poem = self.crossover(words_array[i],words_array[i+1],cross)\n",
    "                child_population.append(child1_poem)\n",
    "                child_population.append(child2_poem)\n",
    "                sum_syllables1 = self.store_syllables(child1)\n",
    "                sum_syllables2 = self.store_syllables(child2)\n",
    "                poem_error1 = self.Grammar_checker(child1_poem)\n",
    "                poem_error2 = self.Grammar_checker(child2_poem)\n",
    "                coherence1 = self.coherence_checker(child1_poem)\n",
    "                coherence2 = self.coherence_checker(child2_poem)\n",
    "                syllables_count.append(sum_syllables1)\n",
    "                syllables_count.append(sum_syllables2)\n",
    "                grammer_error.append(poem_error1)\n",
    "                grammer_error.append(poem_error2)\n",
    "                coherence_arr.append(coherence1)\n",
    "                coherence_arr.append(coherence2)\n",
    "                words_array_child.append(child1)\n",
    "                words_array_child.append(child2)\n",
    "        else:\n",
    "            for i in range(0,len(words_array)-1,2):\n",
    "                # print(words_array[i],words_array[i+1])\n",
    "                child1,child2,child1_poem,child2_poem = self.crossover(words_array[i],words_array[i+1],cross)\n",
    "                child_population.append(child1_poem)\n",
    "                child_population.append(child2_poem)\n",
    "                sum_syllables1 = self.store_syllables(child1)\n",
    "                sum_syllables2 = self.store_syllables(child2)\n",
    "                poem_error1 = self.Grammar_checker(child1_poem)\n",
    "                poem_error2 = self.Grammar_checker(child2_poem)\n",
    "                coherence1 = self.coherence_checker(child1_poem)\n",
    "                coherence2 = self.coherence_checker(child2_poem)\n",
    "                syllables_count.append(sum_syllables1)\n",
    "                syllables_count.append(sum_syllables2)\n",
    "                grammer_error.append(poem_error1)\n",
    "                grammer_error.append(poem_error2)\n",
    "                coherence_arr.append(coherence1)\n",
    "                coherence_arr.append(coherence2)\n",
    "                words_array_child.append(child1)\n",
    "                words_array_child.append(child2)\n",
    "        words_array_child = pd.DataFrame(dict(zip([\"words_array\"],[words_array_child])))\n",
    "        Final1 = np.hstack((child_population,syllables_count,grammer_error,coherence_arr))\n",
    "        child_data = pd.DataFrame(Final1,columns=[\"Line1\",\"Line2\",\"Line3\",\"Line4\",\"Syllables1\",\"Syllables2\",\"Syllables3\",\"Syllables4\",\"GrammarError\",\"Coherence\"])\n",
    "        \n",
    "######### Calculate Fitness of Child Poems\n",
    "        max_rank = len(child_data[\"Line1\"])\n",
    "        child_data[\"Gram_Rank\"] = child_data[\"GrammarError\"].rank(method = 'min', ascending = False)\n",
    "        child_data[\"Coherence\"] = child_data[\"Coherence\"].apply(lambda x: [float(el) for el in x.strip(\"[]\").split(\",\")])\n",
    "        child_data[\"Coh_Rank\"] = child_data[\"Coherence\"].rank(method = 'min')\n",
    "        child_data[\"Syll_Bonus\"] = child_data.apply(lambda row: 1 if ((row.Syllables1 == 5)&(row.Syllables2 == 6)&(row.Syllables3 == 6)&(row.Syllables4 == 5)) else 0, axis = 1)\n",
    "        child_data[\"Fitness\"] = child_data.apply(lambda row: 0.4*row.Gram_Rank/max_rank + 0.4*row.Coh_Rank/max_rank + 0.2*row.Syll_Bonus, axis = 1)\n",
    "########        \n",
    "        child_data = pd.concat([child_data,words_array_child],axis=1)\n",
    "        child_data = child_data.reset_index(drop=True)\n",
    "        print()\n",
    "        # print(\"CHILD\")\n",
    "        # display(child_data)\n",
    "        return child_data\n",
    "\n",
    "    def selection_from_child_parents(self,x,child_data,selected_Pop_data):\n",
    "        reduce = (len(list(child_data.index)) + len(list(selected_Pop_data.index))) - x\n",
    "        n = int(reduce/3)\n",
    "        p = reduce - n\n",
    "        if reduce > len(list(child_data.index)) + len(list(selected_Pop_data.index)):\n",
    "            print(\"ERROR\")\n",
    "        else:\n",
    "            if n > len(child_data):\n",
    "                n = len(child_data)\n",
    "                p = reduce - p\n",
    "            if n == 0:\n",
    "                n = 1\n",
    "                p = 1\n",
    "        d = pd.concat([selected_Pop_data,child_data],axis=0)\n",
    "        d = d.reset_index(drop=True)\n",
    "        # print(\"p:\",p)\n",
    "        # print(\"n:\",n)\n",
    "        random_number1 = random.sample(list(selected_Pop_data.index),p)\n",
    "        random_number2 = random.sample(list(range(len(list(selected_Pop_data.index)),len(list(d.index)))),n)\n",
    "        random_number1.extend(random_number2)\n",
    "        # print(random_number1)\n",
    "        for i in random_number1:\n",
    "          d.drop(i,axis=0,inplace = True)\n",
    "        d = d.reset_index(drop=True)\n",
    "        # print(\"NEW POPULATION\")\n",
    "        # display(d)\n",
    "        r = d[[\"Line1\",\"Line2\",\"Line3\",\"Line4\"]]\n",
    "        return d,r\n",
    "    \n",
    "    def __init__(self,words_df,n,cross,epoch,z):\n",
    "        Selection_number = int(round(0.85*n))\n",
    "        best = []\n",
    "        assert n>1 ,f\"Population {n} cannot be less than or equal to 1\"\n",
    "        # assert n>=Selection_number, f\"Cannot select {Selection_number} poems from total population of {n}\"\n",
    "        assert cross>1, f\"Minimum number for crossover should be 1\"\n",
    "        # assert 2*n >= Selection_number ,f\"Cannot make initial population of {n} if only {Selection_number} parents are selected\"\n",
    "\n",
    "        Population_data = self.create_set_of_poems(n)\n",
    "        for i in range(epoch):\n",
    "            Selected_Population_data,selected_polulation_word_array = self.tournament(Population_data,Selection_number,best)\n",
    "            child_population = self.child_poems(selected_polulation_word_array,cross)\n",
    "            final_population,final_poems = self.selection_from_child_parents(n,child_population,Population_data)\n",
    "            if i != epoch-1:\n",
    "                if (i+1)%10 == 0: # User feedback every 10 epochs\n",
    "                    print(\"Select best poems\")\n",
    "                    display(final_poems)\n",
    "                    best = (list(map(int,input(\"\\n Enter best poems numbers: \").strip().split())))[:z]\n",
    "                Population_data = final_population\n",
    "                print(\"Final poems\")\n",
    "                display(final_population)\n",
    "\n",
    "            else:\n",
    "                print(\"###################################################\")\n",
    "                print(\"Last Poems Standing\")\n",
    "                print(\"###################################################\")\n",
    "                display(final_population)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final poems\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line1</th>\n",
       "      <th>Line2</th>\n",
       "      <th>Line3</th>\n",
       "      <th>Line4</th>\n",
       "      <th>Syllables1</th>\n",
       "      <th>Syllables2</th>\n",
       "      <th>Syllables3</th>\n",
       "      <th>Syllables4</th>\n",
       "      <th>GrammarError</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Gram_Rank</th>\n",
       "      <th>Coh_Rank</th>\n",
       "      <th>Syll_Bonus</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>words_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know mortal pinpoint misses</td>\n",
       "      <td>her trees feel be</td>\n",
       "      <td>word to of burden</td>\n",
       "      <td>turned you figments call</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>[8.63054782402313e-06]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of, burden, turned, you, figments, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are let having knew</td>\n",
       "      <td>road enigma its here</td>\n",
       "      <td>be observed world that</td>\n",
       "      <td>as were pleasing souls</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[are, let, having, knew, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lives and organs hand</td>\n",
       "      <td>forgiveness design of ever</td>\n",
       "      <td>her emptiness me may</td>\n",
       "      <td>fond the in knowledge</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>[2.7569805548962773e-05]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>[lives, and, organs, hand, forgiveness, design, of, ever, her, emptiness, me, may, fond, the, in, knowledge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finality to causing after</td>\n",
       "      <td>a without i let</td>\n",
       "      <td>i fear clap all</td>\n",
       "      <td>there upon the its</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>[3.416258513675822e-05]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[finality, to, causing, after, a, without, i, let, i, fear, clap, all, there, upon, the, its]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into years holds is</td>\n",
       "      <td>moved for so how</td>\n",
       "      <td>together we let having</td>\n",
       "      <td>knew are devour me</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[into, years, holds, is, moved, for, so, how, together, we, let, having, knew, are, devour, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keeping by is remembering</td>\n",
       "      <td>road enigma its here</td>\n",
       "      <td>be observed world that</td>\n",
       "      <td>as were pleasing souls</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>[7.705846271449224e-06]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[keeping, by, is, remembering, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>call causing after a</td>\n",
       "      <td>without to of know</td>\n",
       "      <td>mortal pinpoint misses her</td>\n",
       "      <td>trees feel be word</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>[9.58949758224792e-06]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[call, causing, after, a, without, to, of, know, mortal, pinpoint, misses, her, trees, feel, be, word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of every all we</td>\n",
       "      <td>time call for casts</td>\n",
       "      <td>life and flying in</td>\n",
       "      <td>turning and delight on</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.00017415212573475243]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[of, every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>into appear city upright</td>\n",
       "      <td>dressed alive unique has</td>\n",
       "      <td>heart trees we within</td>\n",
       "      <td>a relevant spirited of</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[into, appear, city, upright, dressed, alive, unique, has, heart, trees, we, within, a, relevant, spirited, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a a long chest</td>\n",
       "      <td>our never pleasing losers</td>\n",
       "      <td>knell that cold life</td>\n",
       "      <td>eye inside like alive</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>[8.434399009840786e-05]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[a, a, long, chest, our, never, pleasing, losers, knell, that, cold, life, eye, inside, like, alive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Line1                       Line2  \\\n",
       "0  know mortal pinpoint misses           her trees feel be   \n",
       "1          are let having knew        road enigma its here   \n",
       "2        lives and organs hand  forgiveness design of ever   \n",
       "3    finality to causing after             a without i let   \n",
       "4          into years holds is            moved for so how   \n",
       "5    keeping by is remembering        road enigma its here   \n",
       "6         call causing after a          without to of know   \n",
       "7              of every all we         time call for casts   \n",
       "8     into appear city upright    dressed alive unique has   \n",
       "9               a a long chest   our never pleasing losers   \n",
       "\n",
       "                        Line3                     Line4 Syllables1 Syllables2  \\\n",
       "0           word to of burden  turned you figments call          7          4   \n",
       "1      be observed world that    as were pleasing souls          6          7   \n",
       "2        her emptiness me may     fond the in knowledge          6          9   \n",
       "3             i fear clap all        there upon the its          9          5   \n",
       "4      together we let having        knew are devour me          5          5   \n",
       "5      be observed world that    as were pleasing souls          8          7   \n",
       "6  mortal pinpoint misses her        trees feel be word          6          5   \n",
       "7          life and flying in    turning and delight on          6          4   \n",
       "8       heart trees we within    a relevant spirited of          8          9   \n",
       "9        knell that cold life     eye inside like alive          4          7   \n",
       "\n",
       "  Syllables3 Syllables4 GrammarError                 Coherence  Gram_Rank  \\\n",
       "0          5          6           17    [8.63054782402313e-06]        7.0   \n",
       "1          6          6           11                     [0.0]       10.0   \n",
       "2          6          6           23  [2.7569805548962773e-05]        2.0   \n",
       "3          4          6           15   [3.416258513675822e-05]        8.0   \n",
       "4          7          6           21                     [0.0]        2.0   \n",
       "5          6          6           15   [7.705846271449224e-06]        6.0   \n",
       "6          7          4           22    [9.58949758224792e-06]        1.0   \n",
       "7          4          6           17  [0.00017415212573475243]        4.0   \n",
       "8          5          8           17                     [0.0]        4.0   \n",
       "9          4          8           12   [8.434399009840786e-05]        8.0   \n",
       "\n",
       "   Coh_Rank  Syll_Bonus  Fitness  \\\n",
       "0       4.0           0     0.44   \n",
       "1       1.0           0     0.44   \n",
       "2       6.0           0     0.32   \n",
       "3       7.0           0     0.60   \n",
       "4       1.0           0     0.15   \n",
       "5       4.0           0     0.50   \n",
       "6       5.0           0     0.30   \n",
       "7       8.0           0     0.60   \n",
       "8       1.0           0     0.25   \n",
       "9       7.0           0     0.75   \n",
       "\n",
       "                                                                                                       words_array  \n",
       "0        [know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of, burden, turned, you, figments, call]  \n",
       "1          [are, let, having, knew, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]  \n",
       "2     [lives, and, organs, hand, forgiveness, design, of, ever, her, emptiness, me, may, fond, the, in, knowledge]  \n",
       "3                    [finality, to, causing, after, a, without, i, let, i, fear, clap, all, there, upon, the, its]  \n",
       "4                  [into, years, holds, is, moved, for, so, how, together, we, let, having, knew, are, devour, me]  \n",
       "5    [keeping, by, is, remembering, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]  \n",
       "6           [call, causing, after, a, without, to, of, know, mortal, pinpoint, misses, her, trees, feel, be, word]  \n",
       "7                   [of, every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on]  \n",
       "8  [into, appear, city, upright, dressed, alive, unique, has, heart, trees, we, within, a, relevant, spirited, of]  \n",
       "9             [a, a, long, chest, our, never, pleasing, losers, knell, that, cold, life, eye, inside, like, alive]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Last Poems Standing\n",
      "###################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line1</th>\n",
       "      <th>Line2</th>\n",
       "      <th>Line3</th>\n",
       "      <th>Line4</th>\n",
       "      <th>Syllables1</th>\n",
       "      <th>Syllables2</th>\n",
       "      <th>Syllables3</th>\n",
       "      <th>Syllables4</th>\n",
       "      <th>GrammarError</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Gram_Rank</th>\n",
       "      <th>Coh_Rank</th>\n",
       "      <th>Syll_Bonus</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>words_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know mortal pinpoint misses</td>\n",
       "      <td>her trees feel be</td>\n",
       "      <td>word to of burden</td>\n",
       "      <td>turned you figments call</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>[8.63054782402313e-06]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of, burden, turned, you, figments, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are let having knew</td>\n",
       "      <td>road enigma its here</td>\n",
       "      <td>be observed world that</td>\n",
       "      <td>as were pleasing souls</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>[are, let, having, knew, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>into years holds is</td>\n",
       "      <td>moved for so how</td>\n",
       "      <td>together we let having</td>\n",
       "      <td>knew are devour me</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[into, years, holds, is, moved, for, so, how, together, we, let, having, knew, are, devour, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of every all we</td>\n",
       "      <td>time call for casts</td>\n",
       "      <td>life and flying in</td>\n",
       "      <td>turning and delight on</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.00017415212573475243]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[of, every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>souls enigma its here</td>\n",
       "      <td>be observed world that</td>\n",
       "      <td>as were pleasing long</td>\n",
       "      <td>are let having knew</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>[souls, enigma, its, here, be, observed, world, that, as, were, pleasing, long, are, let, having, knew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>let i fear clap</td>\n",
       "      <td>all there finality to</td>\n",
       "      <td>causing after a without</td>\n",
       "      <td>i be observed world</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>[1.5411692542898447e-05]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[let, i, fear, clap, all, there, finality, to, causing, after, a, without, i, be, observed, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that upon the its</td>\n",
       "      <td>as were pleasing souls</td>\n",
       "      <td>keeping by is remembering</td>\n",
       "      <td>road enigma its here</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>[8.990153983357427e-06]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>[that, upon, the, its, as, were, pleasing, souls, keeping, by, is, remembering, road, enigma, its, here]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>every all we time</td>\n",
       "      <td>call for casts life</td>\n",
       "      <td>and flying in turning</td>\n",
       "      <td>and delight on burden</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.00015238311001790838]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>[every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on, burden]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>turned you figments call</td>\n",
       "      <td>of know mortal pinpoint</td>\n",
       "      <td>misses her trees feel</td>\n",
       "      <td>be word to of</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>[9.58949758224792e-06]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>[turned, you, figments, call, of, know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unique has heart trees</td>\n",
       "      <td>we within a relevant</td>\n",
       "      <td>spirited of into appear</td>\n",
       "      <td>city upright dressed alive</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[unique, has, heart, trees, we, within, a, relevant, spirited, of, into, appear, city, upright, dressed, alive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Line1                    Line2  \\\n",
       "0  know mortal pinpoint misses        her trees feel be   \n",
       "1          are let having knew     road enigma its here   \n",
       "2          into years holds is         moved for so how   \n",
       "3              of every all we      time call for casts   \n",
       "4        souls enigma its here   be observed world that   \n",
       "5              let i fear clap    all there finality to   \n",
       "6            that upon the its   as were pleasing souls   \n",
       "7            every all we time      call for casts life   \n",
       "8     turned you figments call  of know mortal pinpoint   \n",
       "9       unique has heart trees     we within a relevant   \n",
       "\n",
       "                       Line3                       Line4 Syllables1  \\\n",
       "0          word to of burden    turned you figments call          7   \n",
       "1     be observed world that      as were pleasing souls          6   \n",
       "2     together we let having          knew are devour me          5   \n",
       "3         life and flying in      turning and delight on          6   \n",
       "4      as were pleasing long         are let having knew          7   \n",
       "5    causing after a without         i be observed world          4   \n",
       "6  keeping by is remembering        road enigma its here          5   \n",
       "7      and flying in turning       and delight on burden          6   \n",
       "8      misses her trees feel               be word to of          6   \n",
       "9    spirited of into appear  city upright dressed alive          6   \n",
       "\n",
       "  Syllables2 Syllables3 Syllables4 GrammarError                 Coherence  \\\n",
       "0          4          5          6           17    [8.63054782402313e-06]   \n",
       "1          7          6          6           11                     [0.0]   \n",
       "2          5          7          6           21                     [0.0]   \n",
       "3          4          4          6           17  [0.00017415212573475243]   \n",
       "4          6          6          6           12                     [0.0]   \n",
       "5          8          7          6           14  [1.5411692542898447e-05]   \n",
       "6          6          8          7           17   [8.990153983357427e-06]   \n",
       "7          4          5          6           15  [0.00015238311001790838]   \n",
       "8          6          5          4           16    [9.58949758224792e-06]   \n",
       "9          7          8          9           20                     [0.0]   \n",
       "\n",
       "   Gram_Rank  Coh_Rank  Syll_Bonus  Fitness  \\\n",
       "0        7.0       4.0           0     0.44   \n",
       "1       10.0       1.0           0     0.44   \n",
       "2        2.0       1.0           0     0.15   \n",
       "3        4.0       8.0           0     0.60   \n",
       "4        8.0       1.0           0     0.45   \n",
       "5        6.0       6.0           0     0.60   \n",
       "6        3.0       4.0           0     0.35   \n",
       "7        5.0       8.0           0     0.65   \n",
       "8        4.0       5.0           0     0.45   \n",
       "9        1.0       1.0           0     0.10   \n",
       "\n",
       "                                                                                                       words_array  \n",
       "0        [know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of, burden, turned, you, figments, call]  \n",
       "1          [are, let, having, knew, road, enigma, its, here, be, observed, world, that, as, were, pleasing, souls]  \n",
       "2                  [into, years, holds, is, moved, for, so, how, together, we, let, having, knew, are, devour, me]  \n",
       "3                   [of, every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on]  \n",
       "4          [souls, enigma, its, here, be, observed, world, that, as, were, pleasing, long, are, let, having, knew]  \n",
       "5               [let, i, fear, clap, all, there, finality, to, causing, after, a, without, i, be, observed, world]  \n",
       "6         [that, upon, the, its, as, were, pleasing, souls, keeping, by, is, remembering, road, enigma, its, here]  \n",
       "7               [every, all, we, time, call, for, casts, life, and, flying, in, turning, and, delight, on, burden]  \n",
       "8            [turned, you, figments, call, of, know, mortal, pinpoint, misses, her, trees, feel, be, word, to, of]  \n",
       "9  [unique, has, heart, trees, we, within, a, relevant, spirited, of, into, appear, city, upright, dressed, alive]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4 (words_df,intial_population,crossover,epochs,user_selection_poems_number):\n",
    "poem = poem_generation(words_df,10,2,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(5,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a = [2,3,4,5]\n",
    "\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
